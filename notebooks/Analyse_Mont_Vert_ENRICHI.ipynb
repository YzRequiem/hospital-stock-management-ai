{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè• Analyse Avanc√©e avec Dataset Enrichi - Clinique du Mont Vert\n",
    "## IA Pr√©dictive avec Prophet + Regressors Externes\n",
    "\n",
    "---\n",
    "\n",
    "**Version ENRICHI - Optimis√©e pour Prophet Avanc√©**\n",
    "\n",
    "**Projet** : Master EISI - Gestion des stocks  \n",
    "**Dataset** : Enrichi v3.0 - 5 ans de donn√©es (2020-2024)  \n",
    "**Lignes** : 85,809 enregistrements  \n",
    "**Colonnes** : 22 (15 base + 7 r√©gresseurs)\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Nouveaut√©s du Dataset Enrichi\n",
    "\n",
    "### üéØ 7 R√©gresseurs Externes\n",
    "- **temperature** : Temp√©rature ext√©rieure (¬∞C)\n",
    "- **taux_occupation** : Taux d'occupation h√¥pital (%)\n",
    "- **nb_patients** : Nombre de patients\n",
    "- **epidemie_grippe** : P√©riodes d'√©pid√©mie (0/1)\n",
    "- **vacances_scolaires** : Vacances scolaires (0/1)\n",
    "- **jour_ferie** : Jours f√©ri√©s fran√ßais (0/1)\n",
    "- **covid_impact** : P√©riodes COVID (0/1)\n",
    "\n",
    "### üîÑ Changepoints Majeurs\n",
    "- **15/03/2020** : COVID-19 Vague 1 (+50%)\n",
    "- **01/11/2020** : COVID-19 Vague 2 (+30%)\n",
    "- **01/05/2021** : D√©confinement (-10%)\n",
    "- **01/01/2022** : Nouvelle Direction (+10%)\n",
    "- **01/09/2023** : Extension H√¥pital (+15%)\n",
    "\n",
    "### üìä R√©sultats Attendus\n",
    "- **MAE** : ~2.0 kg (vs 3.5 kg sans regressors)\n",
    "- **MAPE** : ~20% (vs 35% sans regressors)\n",
    "- **Pr√©cision** : Excellente\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì¶ √âtape 1 : Imports et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports standards\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import json\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Configuration matplotlib\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (16, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úÖ Imports de base termin√©s !\")\n",
    "print(f\"üìä NumPy version : {np.__version__}\")\n",
    "print(f\"üìä Pandas version : {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Prophet et utilitaires\n",
    "print(\"ü§ñ Import de Prophet...\")\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "    from prophet.plot import plot_yearly, plot_weekly, add_changepoints_to_plot\n",
    "    from prophet.utilities import regressor_coefficients\n",
    "    print(\"‚úÖ Prophet import√© avec succ√®s !\")\n",
    "    PROPHET_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Erreur Prophet : {e}\")\n",
    "    print(\"üí° Installation : pip install prophet\")\n",
    "    PROPHET_AVAILABLE = False\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "if PROPHET_AVAILABLE:\n",
    "    print(\"üéâ Tout est pr√™t pour l'analyse avanc√©e !\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Prophet requis pour ce notebook\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Results Manager (optionnel)\n",
    "try:\n",
    "    from results_manager import ResultsManager\n",
    "    results_mgr = ResultsManager()\n",
    "    results_mgr.create_run_directory()\n",
    "    print(f\"‚úÖ Results Manager activ√©\")\n",
    "    print(f\"üìÅ R√©sultats seront sauvegard√©s dans : {results_mgr.get_run_path()}\")\n",
    "    USE_RESULTS_MANAGER = True\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è  Results Manager non disponible (optionnel)\")\n",
    "    USE_RESULTS_MANAGER = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìÇ √âtape 2 : Chargement du Dataset Enrichi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin du dataset enrichi\n",
    "FICHIER_CSV = \"../data/dataset_stock_hopital_ENRICHI.csv\"\n",
    "\n",
    "# V√©rifier que le fichier existe\n",
    "if not Path(FICHIER_CSV).exists():\n",
    "    print(f\"‚ùå Fichier introuvable : {FICHIER_CSV}\")\n",
    "    print(\"\\nüí° Assurez-vous que le dataset enrichi est dans data/\")\n",
    "    raise FileNotFoundError(f\"Le fichier {FICHIER_CSV} n'existe pas\")\n",
    "\n",
    "# Chargement\n",
    "print(f\"üìä Chargement de {FICHIER_CSV}...\")\n",
    "df = pd.read_csv(FICHIER_CSV)\n",
    "\n",
    "print(f\"‚úÖ Dataset enrichi charg√© avec succ√®s !\")\n",
    "print(f\"üìè Dimensions : {df.shape[0]:,} lignes √ó {df.shape[1]} colonnes\")\n",
    "print(f\"üíæ Taille m√©moire : {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu des donn√©es\n",
    "print(\"üëÄ Aper√ßu des 5 premi√®res lignes :\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier les colonnes du dataset enrichi\n",
    "print(\"üìä COLONNES DU DATASET ENRICHI\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "colonnes_base = ['date', 'id_produit', 'nom_produit', 'type_produit', 'type_operation',\n",
    "                 'type_sortie', 'quantite', 'unite', 'id_lot', 'id_arrivage',\n",
    "                 'id_fournisseur', 'nom_fournisseur', 'date_expiration',\n",
    "                 'stock_theorique', 'temperature_stockage']\n",
    "\n",
    "regresseurs = ['temperature', 'taux_occupation', 'nb_patients', 'epidemie_grippe',\n",
    "               'vacances_scolaires', 'jour_ferie', 'covid_impact']\n",
    "\n",
    "print(\"\\n‚úÖ Colonnes de base (15) :\")\n",
    "for col in colonnes_base:\n",
    "    if col in df.columns:\n",
    "        print(f\"   ‚úì {col}\")\n",
    "    else:\n",
    "        print(f\"   ‚úó {col} (manquante)\")\n",
    "\n",
    "print(\"\\n‚úÖ R√©gresseurs externes (7) :\")\n",
    "for col in regresseurs:\n",
    "    if col in df.columns:\n",
    "        print(f\"   ‚úì {col}\")\n",
    "    else:\n",
    "        print(f\"   ‚úó {col} (manquante)\")\n",
    "\n",
    "print(f\"\\nüìä Total colonnes trouv√©es : {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßπ √âtape 3 : Pr√©paration des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion des dates\n",
    "print(\"üìÖ Conversion des colonnes de dates...\")\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['date_expiration'] = pd.to_datetime(df['date_expiration'])\n",
    "\n",
    "print(\"‚úÖ Dates converties !\")\n",
    "print(f\"üìÜ P√©riode couverte : {df['date'].min().date()} ‚Üí {df['date'].max().date()}\")\n",
    "print(f\"‚è±Ô∏è  Dur√©e totale : {(df['date'].max() - df['date'].min()).days} jours\")\n",
    "print(f\"üìä Soit {(df['date'].max() - df['date'].min()).days / 365:.1f} ans de donn√©es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques sur les r√©gresseurs\n",
    "print(\"üìä STATISTIQUES DES R√âGRESSEURS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüå°Ô∏è  Temp√©rature :\")\n",
    "print(f\"   Moyenne : {df['temperature'].mean():.1f}¬∞C\")\n",
    "print(f\"   Min/Max : {df['temperature'].min():.1f}¬∞C / {df['temperature'].max():.1f}¬∞C\")\n",
    "\n",
    "print(f\"\\nüè• Taux d'occupation :\")\n",
    "print(f\"   Moyenne : {df['taux_occupation'].mean():.1f}%\")\n",
    "print(f\"   Min/Max : {df['taux_occupation'].min():.1f}% / {df['taux_occupation'].max():.1f}%\")\n",
    "\n",
    "print(f\"\\nüë• Nombre de patients :\")\n",
    "print(f\"   Moyenne : {df['nb_patients'].mean():.0f} patients/jour\")\n",
    "print(f\"   Min/Max : {df['nb_patients'].min():.0f} / {df['nb_patients'].max():.0f}\")\n",
    "\n",
    "print(f\"\\nü¶† √âpid√©mies de grippe :\")\n",
    "nb_jours_grippe = df['epidemie_grippe'].sum()\n",
    "pct_grippe = (nb_jours_grippe / len(df) * 100)\n",
    "print(f\"   {nb_jours_grippe:,} jours d'√©pid√©mie ({pct_grippe:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüèñÔ∏è  Vacances scolaires :\")\n",
    "nb_jours_vacances = df['vacances_scolaires'].sum()\n",
    "pct_vacances = (nb_jours_vacances / len(df) * 100)\n",
    "print(f\"   {nb_jours_vacances:,} jours de vacances ({pct_vacances:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüìÖ Jours f√©ri√©s :\")\n",
    "nb_jours_feries = df['jour_ferie'].sum()\n",
    "nb_annees = (df['date'].max() - df['date'].min()).days / 365\n",
    "print(f\"   {nb_jours_feries:,} jours f√©ri√©s (~{nb_jours_feries/nb_annees:.0f}/an)\")\n",
    "\n",
    "print(f\"\\nüò∑ Impact COVID :\")\n",
    "nb_jours_covid = df['covid_impact'].sum()\n",
    "pct_covid = (nb_jours_covid / len(df) * 100)\n",
    "print(f\"   {nb_jours_covid:,} jours impact√©s ({pct_covid:.1f}%)\")\n",
    "print(f\"   Soit {nb_jours_covid/30:.0f} mois cumul√©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ √âtape 4 : S√©lection du Produit √† Analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir le produit √† analyser\n",
    "PRODUIT_ANALYSE = \"Poulet frais\"  # ‚Üê Changez ici pour analyser un autre produit\n",
    "\n",
    "print(f\"üîç ANALYSE APPROFONDIE : {PRODUIT_ANALYSE}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Filtrer uniquement les sorties de consommation (pas les destructions)\n",
    "produit_df = df[\n",
    "    (df['nom_produit'] == PRODUIT_ANALYSE) &\n",
    "    (df['type_sortie'] == 'CONSOMMATION')\n",
    "].copy()\n",
    "\n",
    "if len(produit_df) == 0:\n",
    "    print(f\"‚ùå Aucune donn√©e trouv√©e pour '{PRODUIT_ANALYSE}'\")\n",
    "    print(\"\\nüí° Produits disponibles :\")\n",
    "    print(df['nom_produit'].unique())\n",
    "else:\n",
    "    print(f\"üìä {len(produit_df):,} sorties enregistr√©es\")\n",
    "    print(f\"üìÖ P√©riode : {produit_df['date'].min().date()} ‚Üí {produit_df['date'].max().date()}\")\n",
    "    print(f\"üì¶ Volume total : {produit_df['quantite'].sum():,.2f} kg\")\n",
    "    print(f\"üìà Moyenne/sortie : {produit_df['quantite'].mean():.2f} kg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä √âtape 5 : Agr√©gation Quotidienne avec R√©gresseurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agr√©ger par jour en gardant les r√©gresseurs\n",
    "print(\"üîß Agr√©gation des donn√©es par jour...\")\n",
    "\n",
    "daily = produit_df.groupby('date').agg({\n",
    "    'quantite': 'sum',                    # Somme des quantit√©s consomm√©es\n",
    "    'temperature': 'mean',                # Moyenne temp√©rature du jour\n",
    "    'taux_occupation': 'mean',            # Moyenne taux occupation\n",
    "    'nb_patients': 'mean',                # Moyenne nb patients\n",
    "    'epidemie_grippe': 'max',             # 1 si √©pid√©mie ce jour\n",
    "    'vacances_scolaires': 'max',          # 1 si vacances ce jour\n",
    "    'jour_ferie': 'max',                  # 1 si f√©ri√© ce jour\n",
    "    'covid_impact': 'max'                 # 1 si COVID ce jour\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"‚úÖ {len(daily)} jours avec donn√©es\")\n",
    "\n",
    "# Compl√©ter les dates manquantes avec 0\n",
    "print(\"üîß Compl√©tion des dates manquantes...\")\n",
    "date_range = pd.date_range(\n",
    "    start=daily['date'].min(),\n",
    "    end=daily['date'].max(),\n",
    "    freq='D'\n",
    ")\n",
    "full_dates = pd.DataFrame({'date': date_range})\n",
    "daily = full_dates.merge(daily, on='date', how='left')\n",
    "\n",
    "# Remplir les valeurs manquantes\n",
    "daily['quantite'].fillna(0, inplace=True)  # Pas de consommation = 0\n",
    "\n",
    "# Pour les r√©gresseurs continus : utiliser la moyenne\n",
    "for col in ['temperature', 'taux_occupation', 'nb_patients']:\n",
    "    daily[col].fillna(daily[col].mean(), inplace=True)\n",
    "\n",
    "# Pour les r√©gresseurs binaires : utiliser 0\n",
    "for col in ['epidemie_grippe', 'vacances_scolaires', 'jour_ferie', 'covid_impact']:\n",
    "    daily[col].fillna(0, inplace=True)\n",
    "\n",
    "print(f\"‚úÖ {len(daily)} jours pr√©par√©s (toutes les dates)\")\n",
    "print(f\"   - Jours avec consommation : {(daily['quantite'] > 0).sum()}\")\n",
    "print(f\"   - Jours sans consommation : {(daily['quantite'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©parer le DataFrame pour Prophet\n",
    "print(\"üîß Pr√©paration pour Prophet (renommage ds/y)...\")\n",
    "\n",
    "prophet_df = daily.copy()\n",
    "prophet_df = prophet_df.rename(columns={'date': 'ds', 'quantite': 'y'})\n",
    "\n",
    "print(f\"‚úÖ DataFrame Prophet pr√™t\")\n",
    "print(f\"   - ds (date) : {prophet_df['ds'].min()} ‚Üí {prophet_df['ds'].max()}\")\n",
    "print(f\"   - y (quantit√©) : moyenne = {prophet_df['y'].mean():.2f} kg/jour\")\n",
    "print(f\"   - R√©gresseurs : {', '.join(['temperature', 'taux_occupation', 'nb_patients', 'epidemie_grippe'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# üìÖ √âtape 6 : Configuration des Holidays (Jours F√©ri√©s)\n\nProphet permet de mod√©liser des √©v√©nements sp√©ciaux via le syst√®me de \"holidays\".\nNous allons cr√©er **3 types de holidays** :\n\n1. **Jours f√©ri√©s fran√ßais** (No√´l, 14 juillet, etc.)\n2. **Vacances scolaires** (zones A, B, C)\n3. **P√©riodes COVID** (√©v√©nement majeur exceptionnel)\n\nCes √©v√©nements ont un impact important sur la consommation hospitali√®re :\n- Les jours f√©ri√©s = moins de personnel = moins de consommation\n- Les vacances = moins d'admissions = consommation r√©duite\n- COVID = confinement + surcharge = consommation augment√©e",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Cr√©er le DataFrame des jours f√©ri√©s\nprint(\"üìÖ CONFIGURATION DES HOLIDAYS\")\nprint(\"=\"*70)\n\n# 1. Jours f√©ri√©s fran√ßais\nholidays_jf = daily[daily['jour_ferie'] == 1][['date']].drop_duplicates()\nholidays_jf.columns = ['ds']\nholidays_jf['holiday'] = 'jour_ferie'\nholidays_jf['lower_window'] = 0\nholidays_jf['upper_window'] = 0\n\nprint(f\"\\n‚úÖ Jours f√©ri√©s : {len(holidays_jf)} jours\")\n\n# 2. Vacances scolaires\nholidays_vac = daily[daily['vacances_scolaires'] == 1][['date']].drop_duplicates()\nholidays_vac.columns = ['ds']\nholidays_vac['holiday'] = 'vacances_scolaires'\nholidays_vac['lower_window'] = 0\nholidays_vac['upper_window'] = 0\n\nprint(f\"‚úÖ Vacances scolaires : {len(holidays_vac)} jours\")\n\n# 3. P√©riodes COVID (√©v√©nement majeur)\nholidays_covid = daily[daily['covid_impact'] == 1][['date']].drop_duplicates()\nholidays_covid.columns = ['ds']\nholidays_covid['holiday'] = 'covid_19'\nholidays_covid['lower_window'] = 0\nholidays_covid['upper_window'] = 0\n\nprint(f\"‚úÖ P√©riodes COVID : {len(holidays_covid)} jours\")\n\n# Combiner tous les holidays\nholidays = pd.concat([holidays_jf, holidays_vac, holidays_covid])\n\nprint(f\"\\nüìä Total holidays configur√©s : {len(holidays)} jours\")\nprint(f\"\\nTypes de holidays :\")\nprint(holidays['holiday'].value_counts())",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Aper√ßu des holidays\nprint(\"\\nüëÄ Aper√ßu des 10 premiers holidays :\")\nholidays.head(10)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# üîÑ √âtape 7 : Configuration des Changepoints\n\nLes **changepoints** sont des moments o√π la tendance du mod√®le peut changer brusquement.\n\nProphet peut les d√©tecter automatiquement, mais nous pouvons aussi les sp√©cifier **manuellement** pour les √©v√©nements importants que nous connaissons.\n\n### üí° Pourquoi des changepoints manuels ?\n\nDans notre dataset enrichi, nous connaissons 5 √©v√©nements majeurs qui ont impact√© la consommation :\n\n| Date | √âv√©nement | Impact |\n|------|-----------|--------|\n| **15/03/2020** | COVID-19 Vague 1 | +50% consommation |\n| **01/11/2020** | COVID-19 Vague 2 | +30% consommation |\n| **01/05/2021** | D√©confinement | -10% consommation |\n| **01/01/2022** | Nouvelle Direction | +10% consommation |\n| **01/09/2023** | Extension H√¥pital | +15% consommation |\n\nEn sp√©cifiant ces dates, nous aidons Prophet √† mieux capturer ces changements de tendance.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# D√©finir les changepoints manuellement\nprint(\"üîÑ CONFIGURATION DES CHANGEPOINTS\")\nprint(\"=\"*70)\n\n# Dates des √©v√©nements majeurs (format YYYY-MM-DD)\nchangepoints_manuels = [\n    '2020-03-15',  # COVID-19 Vague 1\n    '2020-11-01',  # COVID-19 Vague 2\n    '2021-05-01',  # D√©confinement\n    '2022-01-01',  # Nouvelle Direction\n    '2023-09-01'   # Extension H√¥pital\n]\n\nprint(f\"\\n‚úÖ {len(changepoints_manuels)} changepoints manuels d√©finis :\")\nfor i, cp in enumerate(changepoints_manuels, 1):\n    print(f\"   {i}. {cp}\")\n\nprint(f\"\\nüí° Note importante :\")\nprint(f\"   Prophet peut aussi d√©tecter automatiquement d'autres changepoints\")\nprint(f\"   ‚Üí Param√®tre : changepoint_prior_scale\")\nprint(f\"   ‚Üí Plus ce param√®tre est √©lev√©, plus le mod√®le est flexible\")\nprint(f\"   ‚Üí Valeur par d√©faut : 0.05 (peu flexible)\")\nprint(f\"   ‚Üí Valeur recommand√©e pour notre dataset : 0.5 (plus flexible)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# üìä √âtape 8 : Split Train/Test\n\nPour √©valuer la performance de notre mod√®le, nous devons diviser nos donn√©es en deux parties :\n\n### üéØ Principe du Split\n\n- **Train (Entra√Ænement)** : Donn√©es que le mod√®le va utiliser pour apprendre les patterns\n- **Test (Validation)** : Donn√©es r√©serv√©es pour √©valuer la performance\n\n### üìê Notre Strat√©gie\n\nNous avons **5 ans de donn√©es** (2020-2024). Nous allons utiliser :\n\n- **Train** : Les 4 premi√®res ann√©es (~80% des donn√©es)\n- **Test** : La derni√®re ann√©e (~20% des donn√©es)\n\n### üí° Pourquoi 1 an de test ?\n\n- C'est suffisant pour capturer toutes les variations saisonni√®res (4 saisons compl√®tes)\n- Cela nous permet de tester la capacit√© du mod√®le √† pr√©dire sur une p√©riode longue\n- C'est une pratique standard en time series forecasting",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Split train/test\nprint(\"üìä SPLIT TRAIN/TEST\")\nprint(\"=\"*70)\n\n# Garder la derni√®re ann√©e pour le test (365 jours)\nsplit_date = prophet_df['ds'].max() - pd.Timedelta(days=365)\ntrain = prophet_df[prophet_df['ds'] <= split_date].copy()\ntest = prophet_df[prophet_df['ds'] > split_date].copy()\n\nprint(f\"\\n‚úÖ Donn√©es divis√©es :\")\nprint(f\"   üìÖ Date de split : {split_date.date()}\")\nprint(f\"\\n   üéì Train : {len(train)} jours ({train['ds'].min().date()} ‚Üí {train['ds'].max().date()})\")\nprint(f\"   üß™ Test  : {len(test)} jours ({test['ds'].min().date()} ‚Üí {test['ds'].max().date()})\")\nprint(f\"\\n   üìä Ratio : {len(train)/len(prophet_df)*100:.1f}% train / {len(test)/len(prophet_df)*100:.1f}% test\")\n\n# V√©rifier que le test contient bien des r√©gresseurs\nprint(f\"\\n‚úÖ V√©rification des r√©gresseurs dans le test :\")\nprint(f\"   - Temperature : {test['temperature'].notna().sum()} valeurs\")\nprint(f\"   - Taux occupation : {test['taux_occupation'].notna().sum()} valeurs\")\nprint(f\"   - Nb patients : {test['nb_patients'].notna().sum()} valeurs\")\nprint(f\"   - Epidemie grippe : {test['epidemie_grippe'].notna().sum()} valeurs\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# ü§ñ √âtape 9 : Mod√®le Prophet avec Regressors\n\nC'est l'√©tape la plus importante ! Nous allons configurer un mod√®le Prophet **avanc√©** avec toutes les fonctionnalit√©s.\n\n### üéØ Configuration Compl√®te\n\nNotre mod√®le va int√©grer :\n\n1. **Holidays** ‚Üí Jours f√©ri√©s, vacances, COVID\n2. **Changepoints** ‚Üí 5 √©v√©nements majeurs manuels\n3. **Seasonality** ‚Üí Saisonnalit√© annuelle (20) + hebdomadaire (5)\n4. **Regressors** ‚Üí 4 variables externes (temp√©rature, occupation, patients, grippe)\n\n### üìä Param√®tres D√©taill√©s\n\n| Param√®tre | Valeur | Explication |\n|-----------|--------|-------------|\n| `yearly_seasonality` | 20 | Fourier order pour capturer les cycles annuels (default: 10) |\n| `weekly_seasonality` | 5 | Fourier order pour les cycles hebdomadaires (default: 3) |\n| `seasonality_mode` | multiplicative | Effet multiplicatif (mieux pour nos donn√©es) |\n| `changepoint_prior_scale` | 0.5 | Flexibilit√© des changepoints (default: 0.05) |\n| `holidays_prior_scale` | 10.0 | Importance des holidays (default: 10) |\n| `interval_width` | 0.85 | Intervalle de confiance √† 85% |",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Configuration du mod√®le Prophet\nprint(\"ü§ñ CONFIGURATION DU MOD√àLE PROPHET\")\nprint(\"=\"*70)\n\n# Cr√©er le mod√®le avec configuration optimale\nmodel = Prophet(\n    # ===== HOLIDAYS =====\n    holidays=holidays,                # Les 3 types configur√©s pr√©c√©demment\n    holidays_prior_scale=10.0,        # Importance des holidays (default: 10)\n    \n    # ===== SEASONALITY =====\n    yearly_seasonality=20,            # Ordre Fourier annuel (default: 10, max: 20)\n    weekly_seasonality=5,             # Ordre Fourier hebdo (default: 3)\n    daily_seasonality=False,          # Pas n√©cessaire pour agr√©gation quotidienne\n    seasonality_mode='multiplicative', # Effet multiplicatif (vs 'additive')\n    seasonality_prior_scale=10.0,     # Flexibilit√© saisonnalit√© (default: 10)\n    \n    # ===== CHANGEPOINTS =====\n    changepoints=changepoints_manuels, # 5 √©v√©nements majeurs\n    changepoint_prior_scale=0.5,      # Flexibilit√© (default: 0.05, plus = flexible)\n    changepoint_range=0.9,            # 90% des donn√©es (default: 0.8)\n    \n    # ===== AUTRES =====\n    interval_width=0.85,              # Intervalle de confiance 85%\n    growth='linear',                  # Croissance lin√©aire (vs 'logistic')\n    mcmc_samples=0                    # 0 = pas de MCMC (plus rapide)\n)\n\nprint(\"\\n‚úÖ Mod√®le cr√©√© avec :\")\nprint(f\"   üéâ Holidays : {len(holidays)} √©v√©nements\")\nprint(f\"   üîÑ Changepoints : {len(changepoints_manuels)} manuels\")\nprint(f\"   üìä Seasonality : yearly (20) + weekly (5)\")\nprint(f\"   üéØ Mode : multiplicative\")\nprint(f\"   üìà Intervalle confiance : 85%\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Ajouter les r√©gresseurs externes\nprint(\"\\nüîß AJOUT DES R√âGRESSEURS EXTERNES\")\nprint(\"=\"*70)\n\n# 1. Temp√©rature (effet sur produits frais/p√©rissables)\nmodel.add_regressor(\n    'temperature',\n    prior_scale=0.5,      # Importance mod√©r√©e\n    standardize=True,     # Normaliser automatiquement (recommand√©)\n    mode='additive'       # Effet additif\n)\nprint(\"‚úÖ R√©gresseur 'temperature' ajout√©\")\nprint(\"   ‚Üí Impact sur produits sensibles √† la temp√©rature\")\n\n# 2. Taux d'occupation (corr√©lation forte avec consommation)\nmodel.add_regressor(\n    'taux_occupation',\n    prior_scale=1.0,      # Importance √©lev√©e (forte corr√©lation)\n    standardize=True,\n    mode='additive'\n)\nprint(\"‚úÖ R√©gresseur 'taux_occupation' ajout√©\")\nprint(\"   ‚Üí Plus de patients = plus de consommation\")\n\n# 3. Nombre de patients (alternative au taux occupation)\nmodel.add_regressor(\n    'nb_patients',\n    prior_scale=0.5,      # Importance mod√©r√©e (redondant avec occupation)\n    standardize=True,\n    mode='additive'\n)\nprint(\"‚úÖ R√©gresseur 'nb_patients' ajout√©\")\nprint(\"   ‚Üí Compl√©ment du taux d'occupation\")\n\n# 4. √âpid√©mie de grippe (√©v√©nement ponctuel √† fort impact)\nmodel.add_regressor(\n    'epidemie_grippe',\n    prior_scale=0.5,      # Importance mod√©r√©e\n    standardize=False,    # D√©j√† binaire (0 ou 1), pas besoin de normaliser\n    mode='additive'\n)\nprint(\"‚úÖ R√©gresseur 'epidemie_grippe' ajout√©\")\nprint(\"   ‚Üí Impact des √©pid√©mies hivernales\")\n\nprint(f\"\\nüìä Total : 4 r√©gresseurs externes configur√©s !\")\nprint(f\"üí° Ces variables vont am√©liorer significativement les pr√©dictions\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Entra√Æner le mod√®le\nprint(\"\\n‚è≥ ENTRA√éNEMENT DU MOD√àLE...\")\nprint(\"=\"*70)\nprint(\"‚è≥ Cela peut prendre 1-2 minutes selon votre machine...\")\nprint(\"   Prophet utilise Stan (optimisation bay√©sienne)\")\n\n# Fit sur les donn√©es d'entra√Ænement\nmodel.fit(train)\n\nprint(\"\\n‚úÖ Mod√®le entra√Æn√© avec succ√®s !\")\nprint(\"   Le mod√®le a appris les patterns sur 4 ans de donn√©es\")\nprint(\"   Nous allons maintenant l'√©valuer sur l'ann√©e de test\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# üìä √âtape 10 : √âvaluation sur le Test\n\nMaintenant que le mod√®le est entra√Æn√©, nous allons √©valuer sa **performance** sur les donn√©es de test (1 an).\n\n### üìê M√©triques Utilis√©es\n\nNous utilisons 3 m√©triques standard pour √©valuer la pr√©cision :\n\n| M√©trique | Nom Complet | Signification | Bon Score |\n|----------|-------------|---------------|-----------|\n| **MAE** | Mean Absolute Error | Erreur moyenne en kg | < 3 kg |\n| **MAPE** | Mean Absolute Percentage Error | Erreur relative en % | < 20% |\n| **RMSE** | Root Mean Squared Error | P√©nalise les grandes erreurs | < 4 kg |\n\n### üí° Interpr√©tation\n\n- **MAE** : \"En moyenne, je me trompe de X kg\"\n- **MAPE** : \"En moyenne, je me trompe de X%\"\n- **RMSE** : \"Mes erreurs les plus importantes sont de l'ordre de X kg\"",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Pr√©dire sur les donn√©es de test\nprint(\"üìä √âVALUATION SUR LE TEST\")\nprint(\"=\"*70)\n\n# G√©n√©rer les pr√©dictions pour la p√©riode de test\npredictions_test = model.predict(test)\n\n# Extraire les valeurs r√©elles et pr√©dites\ny_true = test['y'].values      # Vraies valeurs\ny_pred = predictions_test['yhat'].values  # Pr√©dictions\n\n# Calculer les 3 m√©triques principales\nmae = np.mean(np.abs(y_true - y_pred))\nmape = np.mean(np.abs((y_true - y_pred) / (y_true + 0.01))) * 100  # +0.01 √©vite division par 0\nrmse = np.sqrt(np.mean((y_true - y_pred)**2))\n\n# Afficher les r√©sultats\nprint(f\"\\nüìä M√âTRIQUES DE PERFORMANCE\")\nprint(\"=\"*70)\nprint(f\"MAE  (Erreur Absolue Moyenne)    : {mae:.2f} kg\")\nprint(f\"MAPE (Erreur Relative Moyenne)   : {mape:.2f}%\")\nprint(f\"RMSE (Erreur Quadratique Moyenne): {rmse:.2f} kg\")\nprint(\"=\"*70)\n\n# Interpr√©ter les r√©sultats\nif mape < 15:\n    verdict = \"‚úÖ Excellente pr√©cision ! (MAPE < 15%)\"\n    commentaire = \"Le mod√®le est tr√®s performant. R√©sultats fiables.\"\nelif mape < 25:\n    verdict = \"‚úÖ Bonne pr√©cision (MAPE entre 15% et 25%)\"\n    commentaire = \"Le mod√®le est satisfaisant. Peut √™tre utilis√© en production.\"\nelse:\n    verdict = \"‚ö†Ô∏è  Pr√©cision moyenne (MAPE > 25%)\"\n    commentaire = \"Le mod√®le pourrait √™tre am√©lior√©.\"\n\nprint(f\"\\n{verdict}\")\nprint(f\"üí° {commentaire}\")\nprint(f\"\\nüìà En pratique : Le mod√®le se trompe en moyenne de ¬±{mae:.2f} kg (soit {mape:.1f}%)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# üî¨ √âtape 11 : Analyse des Coefficients des R√©gresseurs\n\nUne des forces de Prophet est qu'il permet d'**interpr√©ter** l'impact de chaque r√©gresseur.\n\n### üí° Qu'est-ce qu'un coefficient ?\n\nLe coefficient repr√©sente **l'impact** d'un r√©gresseur sur la pr√©diction :\n\n- **Coefficient positif** ‚Üí Quand le r√©gresseur augmente, la consommation augmente\n- **Coefficient n√©gatif** ‚Üí Quand le r√©gresseur augmente, la consommation diminue\n\n### üìä Exemple d'Interpr√©tation\n\nSi le coefficient de `taux_occupation` est **+0.25** :\n- Quand le taux d'occupation augmente de 1%, la consommation augmente de ~0.25 kg\n- C'est un **effet positif** : plus de patients = plus de consommation\n\n### üéØ Ce que nous allons analyser\n\n- Impact de la **temp√©rature** sur les produits frais\n- Impact du **taux d'occupation** sur la consommation\n- Impact du **nombre de patients**\n- Impact des **√©pid√©mies de grippe**",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Extraire les coefficients des r√©gresseurs\nprint(\"üî¨ ANALYSE DES COEFFICIENTS DES R√âGRESSEURS\")\nprint(\"=\"*70)\n\ntry:\n    # Utiliser la fonction native de Prophet\n    coeffs = regressor_coefficients(model)\n    \n    print(\"\\nüìä Tableau des coefficients :\")\n    print(coeffs.to_string(index=False))\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"üí° INTERPR√âTATION D√âTAILL√âE\")\n    print(\"=\"*70)\n    \n    # Interpr√©ter chaque coefficient\n    for idx, row in coeffs.iterrows():\n        regressor = row['regressor']\n        coeff = row['coef']\n        coeff_lower = row['coef_lower']\n        coeff_upper = row['coef_upper']\n        \n        # D√©terminer le sens de l'effet\n        if coeff > 0:\n            effet = \"üìà EFFET POSITIF\"\n            interpretation = \"augmente la consommation\"\n        else:\n            effet = \"üìâ EFFET N√âGATIF\"\n            interpretation = \"diminue la consommation\"\n        \n        print(f\"\\nüîπ {regressor.upper()}\")\n        print(f\"   Coefficient : {coeff:+.4f}\")\n        print(f\"   Intervalle  : [{coeff_lower:.4f}, {coeff_upper:.4f}]\")\n        print(f\"   {effet} ‚Üí {interpretation}\")\n        \n        # Interpr√©tation sp√©cifique par r√©gresseur\n        if regressor == 'temperature':\n            if coeff > 0:\n                print(f\"   üí° Plus il fait chaud, plus la consommation augmente (+{abs(coeff):.4f} kg/¬∞C)\")\n            else:\n                print(f\"   üí° Plus il fait chaud, moins la consommation augmente ({coeff:.4f} kg/¬∞C)\")\n        \n        elif regressor == 'taux_occupation':\n            if coeff > 0:\n                print(f\"   üí° 1% d'occupation en plus = +{coeff:.4f} kg de consommation\")\n                print(f\"   üí° Forte corr√©lation attendue : plus de patients = plus de repas\")\n        \n        elif regressor == 'nb_patients':\n            if coeff > 0:\n                print(f\"   üí° 1 patient suppl√©mentaire = +{coeff:.4f} kg\")\n        \n        elif regressor == 'epidemie_grippe':\n            if coeff > 0:\n                print(f\"   üí° En p√©riode d'√©pid√©mie : +{coeff:.4f} kg/jour\")\n            else:\n                print(f\"   üí° En p√©riode d'√©pid√©mie : {coeff:.4f} kg/jour (moins de consommation)\")\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"‚úÖ Analyse des coefficients termin√©e !\")\n    \nexcept Exception as e:\n    print(f\"‚ö†Ô∏è  Impossible d'extraire les coefficients : {e}\")\n    print(\"üí° Cela peut arriver si le mod√®le n'a pas converg√© correctement\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# üîÆ √âtape 12 : Pr√©dictions Futures et Visualisations\n\nMaintenant que notre mod√®le est valid√©, nous allons l'utiliser pour **pr√©dire l'avenir** !\n\n### üéØ Objectif\n\nPr√©dire la consommation pour les **28 prochains jours** (4 semaines) avec intervalles de confiance.\n\n### üìä Processus\n\n1. **R√©entra√Æner** le mod√®le sur **toutes les donn√©es** (train + test)\n2. **Cr√©er** les 28 jours futurs avec valeurs des r√©gresseurs\n3. **Pr√©dire** la consommation future\n4. **Visualiser** les r√©sultats avec 3 graphiques professionnels\n\n### üîß Gestion des R√©gresseurs Futurs\n\nPour les 28 jours futurs, nous devons fournir des valeurs pour nos 4 r√©gresseurs :\n\n| R√©gresseur | Strat√©gie |\n|------------|-----------|\n| `temperature` | Utiliser la moyenne historique |\n| `taux_occupation` | Utiliser la moyenne historique |\n| `nb_patients` | Utiliser la moyenne historique |\n| `epidemie_grippe` | 1 si hiver (janvier-mars), 0 sinon |",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# R√©entra√Æner sur TOUTES les donn√©es (train + test)\nprint(\"üîÆ PR√âDICTIONS FUTURES (28 JOURS)\")\nprint(\"=\"*70)\n\nprint(\"\\n‚è≥ R√©entra√Ænement du mod√®le sur toutes les donn√©es...\")\n\n# Cr√©er un nouveau mod√®le avec la m√™me configuration\nmodel_final = Prophet(\n    holidays=holidays,\n    holidays_prior_scale=10.0,\n    yearly_seasonality=20,\n    weekly_seasonality=5,\n    daily_seasonality=False,\n    seasonality_mode='multiplicative',\n    seasonality_prior_scale=10.0,\n    changepoints=changepoints_manuels,\n    changepoint_prior_scale=0.5,\n    changepoint_range=0.9,\n    interval_width=0.85,\n    growth='linear'\n)\n\n# Ajouter les m√™mes r√©gresseurs\nmodel_final.add_regressor('temperature', prior_scale=0.5, standardize=True)\nmodel_final.add_regressor('taux_occupation', prior_scale=1.0, standardize=True)\nmodel_final.add_regressor('nb_patients', prior_scale=0.5, standardize=True)\nmodel_final.add_regressor('epidemie_grippe', prior_scale=0.5, standardize=False)\n\n# Fit sur TOUTES les donn√©es\nmodel_final.fit(prophet_df)\n\nprint(\"‚úÖ Mod√®le r√©entra√Æn√© sur toutes les donn√©es !\")\nprint(f\"   Donn√©es utilis√©es : {len(prophet_df)} jours\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cr√©er le DataFrame futur avec r√©gresseurs\nprint(\"\\nüîß Cr√©ation des 28 jours futurs avec r√©gresseurs...\")\n\n# Cr√©er les dates futures (28 jours)\nfuture = model_final.make_future_dataframe(periods=28)\n\n# Fusionner avec les r√©gresseurs existants\nfuture = future.merge(\n    prophet_df[['ds', 'temperature', 'taux_occupation', 'nb_patients', 'epidemie_grippe']],\n    on='ds',\n    how='left'\n)\n\n# Pour les jours futurs (NaN), utiliser des valeurs par d√©faut\nprint(\"   Remplissage des r√©gresseurs futurs...\")\n\n# R√©gresseurs continus : moyenne historique\nfor col in ['temperature', 'taux_occupation', 'nb_patients']:\n    mean_value = prophet_df[col].mean()\n    future[col].fillna(mean_value, inplace=True)\n    print(f\"   - {col} : {mean_value:.2f} (moyenne)\")\n\n# √âpid√©mie de grippe : activer si hiver (janvier-mars)\nfuture['epidemie_grippe'].fillna(\n    future['ds'].dt.month.isin([1, 2, 3]).astype(int),\n    inplace=True\n)\nnb_jours_epidemie_futur = future[future['ds'] > prophet_df['ds'].max()]['epidemie_grippe'].sum()\nprint(f\"   - epidemie_grippe : {nb_jours_epidemie_futur} jours d'√©pid√©mie pr√©vus\")\n\nprint(f\"\\n‚úÖ {len(future)} jours pr√©par√©s (historique + 28 futurs)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# G√©n√©rer les pr√©dictions\nprint(\"\\n‚è≥ G√©n√©ration des pr√©dictions...\")\n\nforecast = model_final.predict(future)\n\n# Extraire uniquement les pr√©dictions futures (28 jours)\npredictions_futures = forecast[forecast['ds'] > prophet_df['ds'].max()].copy()\n\nprint(f\"‚úÖ {len(predictions_futures)} jours de pr√©dictions g√©n√©r√©es !\")\nprint(f\"\\nüìä STATISTIQUES DES PR√âDICTIONS\")\nprint(\"=\"*70)\nprint(f\"Total pr√©vu sur 28 jours  : {predictions_futures['yhat'].sum():.2f} kg\")\nprint(f\"Moyenne par jour          : {predictions_futures['yhat'].mean():.2f} kg\")\nprint(f\"Minimum pr√©vu             : {predictions_futures['yhat'].min():.2f} kg\")\nprint(f\"Maximum pr√©vu             : {predictions_futures['yhat'].max():.2f} kg\")\nprint(f\"√âcart-type                : {predictions_futures['yhat'].std():.2f} kg\")\nprint(\"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Aper√ßu des pr√©dictions\nprint(\"\\nüëÄ Aper√ßu des 10 premiers jours de pr√©dictions :\")\npredictions_futures[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head(10)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### üìà Visualisations Professionnelles\n\nNous allons cr√©er **3 graphiques** pour analyser les r√©sultats :\n\n1. **Graphique Principal** : Pr√©dictions avec intervalle de confiance\n2. **Composants** : D√©composition (tendance + saisonnalit√© + holidays)\n3. **Changepoints** : Points de rupture de tendance",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Graphique 1 : Pr√©dictions principales\nprint(\"\\nüìà G√âN√âRATION DES VISUALISATIONS\")\nprint(\"=\"*70)\n\n# Graphique principal avec pr√©dictions\nfig1 = model_final.plot(forecast)\nplt.title(f'Pr√©dictions Prophet - {PRODUIT_ANALYSE}', fontsize=16, fontweight='bold')\nplt.xlabel('Date', fontsize=12)\nplt.ylabel('Consommation (kg)', fontsize=12)\nplt.tight_layout()\n\nfilename1 = f'predictions_{PRODUIT_ANALYSE.replace(\" \", \"_\")}_enrichi.png'\nplt.savefig(filename1, dpi=300, bbox_inches='tight')\nprint(f\"‚úÖ Graphique 1 sauvegard√© : {filename1}\")\nplt.show()\nplt.close()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Graphique 2 : Composants (d√©composition)\nfig2 = model_final.plot_components(forecast)\nplt.tight_layout()\n\nfilename2 = f'components_{PRODUIT_ANALYSE.replace(\" \", \"_\")}_enrichi.png'\nplt.savefig(filename2, dpi=300, bbox_inches='tight')\nprint(f\"‚úÖ Graphique 2 sauvegard√© : {filename2}\")\nprint(\"   ‚Üí Montre la tendance, saisonnalit√© annuelle, hebdomadaire et holidays\")\nplt.show()\nplt.close()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Graphique 3 : Changepoints (points de rupture)\nfig3 = model_final.plot(forecast)\nadd_changepoints_to_plot(fig3.gca(), model_final, forecast)\nplt.title(f'Changepoints - {PRODUIT_ANALYSE}', fontsize=16, fontweight='bold')\nplt.xlabel('Date', fontsize=12)\nplt.ylabel('Consommation (kg)', fontsize=12)\nplt.tight_layout()\n\nfilename3 = f'changepoints_{PRODUIT_ANALYSE.replace(\" \", \"_\")}_enrichi.png'\nplt.savefig(filename3, dpi=300, bbox_inches='tight')\nprint(f\"‚úÖ Graphique 3 sauvegard√© : {filename3}\")\nprint(\"   ‚Üí Montre les 5 changepoints manuels + ceux d√©tect√©s automatiquement\")\nplt.show()\nplt.close()\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"‚úÖ 3 graphiques g√©n√©r√©s avec succ√®s !\")\nprint(\"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# üíæ √âtape 13 : Export des R√©sultats\n\nNous allons maintenant **exporter** tous les r√©sultats dans des formats r√©utilisables :\n\n### üìÅ Fichiers √† Exporter\n\n1. **CSV** : Pr√©dictions des 28 jours avec intervalles de confiance\n2. **JSON** : R√©sum√© complet (m√©triques + param√®tres + recommandations)\n3. **PNG** : Les 3 graphiques g√©n√©r√©s\n\n### üóÇÔ∏è Organisation avec Results Manager\n\nSi le Results Manager est disponible, tous les fichiers seront automatiquement organis√©s dans un dossier horodat√© : `results/YYYYMMDD_HHMMSS/`\n\nCela permet de :\n- Comparer plusieurs ex√©cutions\n- Conserver l'historique des pr√©dictions\n- Retrouver facilement les r√©sultats",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Export CSV des pr√©dictions\nprint(\"üíæ EXPORT DES R√âSULTATS\")\nprint(\"=\"*70)\n\n# Pr√©parer le DataFrame d'export\nexport_df = predictions_futures[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].copy()\nexport_df.columns = ['date', 'quantite_prevue', 'quantite_min', 'quantite_max']\nexport_df['date'] = export_df['date'].dt.date\nexport_df['produit'] = PRODUIT_ANALYSE\nexport_df['confiance'] = '85%'\n\n# R√©organiser les colonnes\nexport_df = export_df[['date', 'produit', 'quantite_prevue', 'quantite_min', 'quantite_max', 'confiance']]\n\n# Sauvegarder\nfilename_csv = f'predictions_{PRODUIT_ANALYSE.replace(\" \", \"_\")}_enrichi_28j.csv'\nexport_df.to_csv(filename_csv, index=False, encoding='utf-8')\nprint(f\"‚úÖ CSV sauvegard√© : {filename_csv}\")\nprint(f\"   ‚Üí {len(export_df)} jours de pr√©dictions\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Export JSON du r√©sum√©\nprint(\"\\nüìÑ Cr√©ation du r√©sum√© JSON...\")\n\nsummary = {\n    \"produit\": PRODUIT_ANALYSE,\n    \"date_analyse\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n    \"dataset\": {\n        \"fichier\": \"dataset_stock_hopital_ENRICHI.csv\",\n        \"version\": \"3.0\",\n        \"nb_lignes_total\": len(df),\n        \"periode\": f\"{df['date'].min().date()} ‚Üí {df['date'].max().date()}\"\n    },\n    \"performance_modele\": {\n        \"MAE\": round(mae, 2),\n        \"MAPE\": round(mape, 2),\n        \"RMSE\": round(rmse, 2),\n        \"methode\": \"Prophet avec regressors enrichis\",\n        \"verdict\": verdict\n    },\n    \"configuration_modele\": {\n        \"holidays\": [\"jour_ferie\", \"vacances_scolaires\", \"covid_19\"],\n        \"nb_holidays\": len(holidays),\n        \"changepoints_manuels\": changepoints_manuels,\n        \"nb_changepoints\": len(changepoints_manuels),\n        \"regresseurs\": [\"temperature\", \"taux_occupation\", \"nb_patients\", \"epidemie_grippe\"],\n        \"seasonality\": {\n            \"yearly\": 20,\n            \"weekly\": 5,\n            \"mode\": \"multiplicative\"\n        }\n    },\n    \"predictions\": {\n        \"horizon\": \"28 jours\",\n        \"periode\": f\"{predictions_futures['ds'].min().date()} ‚Üí {predictions_futures['ds'].max().date()}\",\n        \"total_prevu\": round(predictions_futures['yhat'].sum(), 2),\n        \"moyenne_jour\": round(predictions_futures['yhat'].mean(), 2),\n        \"min_jour\": round(predictions_futures['yhat'].min(), 2),\n        \"max_jour\": round(predictions_futures['yhat'].max(), 2),\n        \"intervalle_confiance\": \"85%\"\n    },\n    \"recommandations\": {\n        \"commande_hebdomadaire\": round(predictions_futures['yhat'].mean() * 7, 2),\n        \"stock_securite\": round(predictions_futures['yhat_upper'].max() * 1.2, 2),\n        \"attention\": \"Tenir compte des variations saisonni√®res\"\n    }\n}\n\nfilename_json = f'summary_{PRODUIT_ANALYSE.replace(\" \", \"_\")}_enrichi.json'\nwith open(filename_json, 'w', encoding='utf-8') as f:\n    json.dump(summary, f, indent=2, ensure_ascii=False)\n\nprint(f\"‚úÖ JSON sauvegard√© : {filename_json}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Sauvegarder avec Results Manager si disponible\nif USE_RESULTS_MANAGER:\n    print(\"\\nüìÅ Sauvegarde avec Results Manager...\")\n    \n    # Sauvegarder les graphiques\n    for filename in [filename1, filename2, filename3]:\n        results_mgr.save_graph(filename)\n        print(f\"   ‚úÖ {filename}\")\n    \n    # Sauvegarder les donn√©es\n    results_mgr.save_data(filename_csv)\n    print(f\"   ‚úÖ {filename_csv}\")\n    \n    results_mgr.save_data(filename_json)\n    print(f\"   ‚úÖ {filename_json}\")\n    \n    # Cr√©er le fichier README automatique\n    results_mgr.create_summary_file(PRODUIT_ANALYSE, summary)\n    \n    print(f\"\\n‚úÖ Tous les r√©sultats sauvegard√©s dans :\")\n    print(f\"   üìÇ {results_mgr.get_run_path()}\")\nelse:\n    print(\"\\nüìÅ Fichiers sauvegard√©s dans le r√©pertoire courant\")\n    print(f\"   üìÑ {filename_csv}\")\n    print(f\"   üìÑ {filename_json}\")\n    print(f\"   üìä {filename1}\")\n    print(f\"   üìä {filename2}\")\n    print(f\"   üìä {filename3}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Afficher le r√©sum√© final\nprint(\"\\n\" + \"=\"*70)\nprint(\"üéâ ANALYSE TERMIN√âE AVEC SUCC√àS !\")\nprint(\"=\"*70)\n\nprint(f\"\\nüìä R√âSUM√â FINAL\")\nprint(\"=\"*70)\nprint(f\"Produit analys√©       : {PRODUIT_ANALYSE}\")\nprint(f\"Dataset utilis√©       : Enrichi v3.0 ({len(df):,} lignes)\")\nprint(f\"Mod√®le                : Prophet avec 4 r√©gresseurs\")\nprint(f\"Performance (MAPE)    : {mape:.2f}%\")\nprint(f\"Pr√©dictions g√©n√©r√©es  : 28 jours ({predictions_futures['yhat'].sum():.2f} kg total)\")\nprint(f\"Graphiques cr√©√©s      : 3 visualisations PNG\")\nprint(f\"Fichiers export√©s     : CSV + JSON\")\nprint(\"=\"*70)\n\nprint(f\"\\nüí° RECOMMANDATIONS\")\nprint(\"=\"*70)\nprint(f\"‚úÖ Commande hebdomadaire sugg√©r√©e : {summary['recommandations']['commande_hebdomadaire']:.2f} kg\")\nprint(f\"‚úÖ Stock de s√©curit√© sugg√©r√©      : {summary['recommandations']['stock_securite']:.2f} kg\")\nprint(f\"‚ö†Ô∏è  Attention : {summary['recommandations']['attention']}\")\nprint(\"=\"*70)\n\nprint(f\"\\nüöÄ PROCHAINES √âTAPES\")\nprint(\"   1. Analyser d'autres produits en changeant PRODUIT_ANALYSE\")\nprint(\"   2. Comparer les r√©sultats avec le dataset de base\")\nprint(\"   3. Ajuster les param√®tres si n√©cessaire\")\nprint(\"   4. Mettre en production les pr√©dictions\")\nprint(\"\\n‚ú® Notebook termin√© ! Vous pouvez maintenant exploiter les r√©sultats.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}